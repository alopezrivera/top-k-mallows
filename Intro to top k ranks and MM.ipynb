{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mallows Kendall\n",
        "### A python package to for the Mallows model with top-$k$ and complete rankings \n",
        "\n",
        "We present methods for working with the Mallows Model (MM), the best-known distribution for permutations. Also, we consider operations for partial rankings (top-$k$ rankings) as well as complete rankings. Cite as \n",
        "\n",
        "Fabien Collas, Ekhine Irurozki (2020). Concentric mixtures of Mallows models for top-k rankings: sampling and identifiability. In ArXiv."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import mallows_kendall_v2 as mk\n",
        "import numpy as np \n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:56:12.335Z",
          "iopub.execute_input": "2021-03-30T07:56:12.351Z",
          "iopub.status.idle": "2021-03-30T07:56:12.612Z",
          "shell.execute_reply": "2021-03-30T07:54:22.352Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Permutations"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generation** The most basic function consists in generating a permutation $\\sigma$ from $S_n$, the set of all permutations. The permutations are coded as vectors of the first $n$ natural numbers (beginning with 0 here in Python) where each item appears once and once only.   \n",
        "Complete permutations can be defined here as `ndarrays` with dtype `int` or `list` of integers as well.  \n",
        "They can be defined by hand as follows:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "perm1 = np.array([3,1,2,0,4])\n",
        "perm1"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "array([3, 1, 2, 0, 4])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:56:12.634Z",
          "iopub.execute_input": "2021-03-30T07:56:12.647Z",
          "iopub.status.idle": "2021-03-30T07:56:12.679Z",
          "shell.execute_reply": "2021-03-30T07:54:22.360Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "They can also be randomly generated as follows ($n$ being the length of the permutation): "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "n=5\n",
        "perm2 = np.random.permutation(n)\n",
        "perm2"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "array([3, 2, 1, 4, 0])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:56:12.703Z",
          "iopub.execute_input": "2021-03-30T07:56:12.716Z",
          "iopub.status.idle": "2021-03-30T07:56:12.745Z",
          "shell.execute_reply": "2021-03-30T07:54:22.367Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Operations** Two permutations can be composed and the result is a permutation. This operation is not commutative in general."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.compose(perm1, perm2)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "array([0, 2, 1, 4, 3])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:56:12.765Z",
          "iopub.execute_input": "2021-03-30T07:56:12.781Z",
          "iopub.status.idle": "2021-03-30T07:56:12.810Z",
          "shell.execute_reply": "2021-03-30T07:54:22.374Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The inverse of a permutation can also be obtained with:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.inverse(perm1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "array([3, 1, 2, 0, 4])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:56:12.830Z",
          "iopub.execute_input": "2021-03-30T07:56:12.845Z",
          "iopub.status.idle": "2021-03-30T07:56:12.874Z",
          "shell.execute_reply": "2021-03-30T07:54:22.381Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distances"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Kendall's-$\\tau$ distance $d(\\sigma, \\pi)$ counts the number of pairwise disagreements beetween $\\sigma$ and $\\pi$, i.e., the number of pairs of positions in which the items are in a particular order in $\\sigma$, and the reverse order in $\\pi$. The Kendall's-$\\tau$ distance between two permutations can be computed as follows: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.kendall_tau(perm1, perm2)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'mallows_kendall_v2' has no attribute 'kendall_tau'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5a68142f5064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkendall_tau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'mallows_kendall_v2' has no attribute 'kendall_tau'"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:56:12.896Z",
          "iopub.execute_input": "2021-03-30T07:56:12.912Z",
          "iopub.status.idle": "2021-03-30T07:54:20.328Z",
          "shell.execute_reply": "2021-03-30T07:54:22.388Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If only one permutation is given in input, it will be assumed that the second permutation is the identity permutation, $e = (1, 2, \\dotsc, n)$."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.kendall_tau(perm1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.353Z",
          "iopub.execute_input": "2021-03-30T07:54:20.370Z",
          "iopub.status.idle": "2021-03-30T07:54:20.406Z",
          "shell.execute_reply": "2021-03-30T07:54:22.395Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum value of the kendall's-$\\tau$ distance between two permutation of length $n$ is $\\frac{n(n-1)}{2}$. It is possible to get this value using the following function: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.max_dist(n)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.432Z",
          "iopub.execute_input": "2021-03-30T07:54:20.450Z",
          "iopub.status.idle": "2021-03-30T07:54:20.489Z",
          "shell.execute_reply": "2021-03-30T07:54:22.402Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each $\\sigma \\in S_n$ there exists a unique vector, called inversion vector of $\\sigma$ with regards to the Kendall's-$\\tau$ distance, denoted $V(\\sigma) = (V_1(\\sigma), \\dotsc, V_{n-1}(\\sigma))$ and such that $d(\\sigma) = \\sum_{j=1}^{n-1}V_j(\\sigma)$.   \n",
        "The $j^{th}$ element $V_j(\\sigma)$ is given by: $V_j(\\sigma) = \\sum\\limits_{i=j+1}^{n}\\mathbb{1}_{\\sigma(i) < \\sigma(j)}$, $\\forall j \\in \\{1, \\dotsc, n-1\\}$. It follows that $0 \\le V_j(\\sigma) \\le n-j$. \n",
        "\n",
        "Finally there is a bijection between each $\\sigma \\in S_n$ and each possible $V(\\sigma)$ inversion vector. In the package the conversion from one form to another is done using the two following functions:  \n",
        "\n",
        "- From $\\sigma$ to $V(\\sigma)$ (here $V$ is of the same length $n$ as the permutation , thus the final $n^{th}$ element of $V$ will always equal $0$) :"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "V_perm1 = mk.ranking_to_v(perm1)\n",
        "V_perm1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.519Z",
          "iopub.execute_input": "2021-03-30T07:54:20.536Z",
          "iopub.status.idle": "2021-03-30T07:54:20.573Z",
          "shell.execute_reply": "2021-03-30T07:54:22.410Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From $V(\\sigma)$ to $\\sigma$ :"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.v_to_ranking(V_perm1, n)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.600Z",
          "iopub.execute_input": "2021-03-30T07:54:20.615Z",
          "iopub.status.idle": "2021-03-30T07:54:20.650Z",
          "shell.execute_reply": "2021-03-30T07:54:22.418Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This package also allows to sample a permutation with a given number of inversions, i.e., at a given distance, where all the posible permutations have the same probability of being generated"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mk.random_perm_at_dist(n, 2, mk.num_perms_at_dist(n))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.672Z",
          "iopub.execute_input": "2021-03-30T07:54:20.686Z",
          "iopub.status.idle": "2021-03-30T07:54:20.721Z",
          "shell.execute_reply": "2021-03-30T07:54:22.425Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*note*: We point out that this notation is taken from Meilǎ, M., Phadnis, K., Patterson, A., & Bilmes, J. (2007). Consensus ranking under the exponential model. In *Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence, UAI 2007* (pp. 285–294). Note thst the definition of the inversion vector difers from the one in the original paper of MM Fligner, M. A., & Verducci, J. S. (1986). Distance based ranking models. Journal of the Royal Statistical Society, 48(3), 359–369.\n",
        "This different versions imply different expressions for the MM which will affect the capability of the MM to be used for partial permutations.\n",
        "\n",
        "# Mallows Model (MM) for complete permutations"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Mallows Model (MM) is an exponential family of probability models for permutation data. We consider $\\sigma$ to be a ranking. Formally, the MM using the Kendall's-$\\tau$ distance is expressed as follows: \n",
        "$$p(\\sigma)=\\dfrac{\\exp(-\\theta d(\\sigma \\sigma_0^{-1}))}{\\psi(\\theta)}$$ \n",
        "where $\\psi(\\theta) =  \\prod_{\\substack{j=1}}^{n-1} \\frac{1-\\exp(-\\theta(n-j+1))}{1 - \\exp(-\\theta)}$.  \n",
        "$\\sigma_0$ represents the central permutation and is the mode of the distribution iff the dispersion parameter $\\theta > 0$. In this case, the greater the distance of a permutation to $\\sigma_0$ the lower is its probability (it decreases exponentially). The dispersion parameter $\\theta$  controls the speed of this fall.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_MM(sigma, sigma_0, theta): \n",
        "    \n",
        "    sigma_0_inv = mk.inverse(sigma_0)\n",
        "    \n",
        "    psi = np.prod(np.array([(1 - np.exp(( - n + j ) * theta))/(1 - np.exp(-theta)) for j in range(n-1)]))\n",
        "    \n",
        "    dist = mk.kendall_tau( mk.compose(sigma, sigma_0_inv) )\n",
        "    \n",
        "    return np.exp( - theta *  dist ) / psi\n",
        "    \n",
        "n = 5    \n",
        "sigma = np.array([3,1,2,0,4])\n",
        "sigma_0 = np.array(range(5))\n",
        "theta = 0.1\n",
        "\n",
        "print(prob_MM(sigma, sigma_0, theta))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.743Z",
          "iopub.execute_input": "2021-03-30T07:54:20.758Z",
          "iopub.status.idle": "2021-03-30T07:54:20.791Z",
          "shell.execute_reply": "2021-03-30T07:54:22.431Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling** This package includes a sampler based on the factorization of the Kendall's-$\\tau$ distance. In the later sections we will also present how this can be adapted to top-$k$ rankings. This differs to the classical sampling, usually done using the Repeated Insertion Model (RIM) and which can not be extended to top-$k$ rankings.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.sampling_mm(m=4,n=5,theta=1.5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.813Z",
          "iopub.execute_input": "2021-03-30T07:54:20.830Z",
          "iopub.status.idle": "2021-03-30T07:54:20.862Z",
          "shell.execute_reply": "2021-03-30T07:54:22.439Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that in the package the sampling functions generates the samples considering $\\sigma_0 = e$, identity permutation by default. But any other central permutation can be given as a parameter.  \n",
        "In practice, we can draw a sample from a MM as follows:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.sampling_mm(m=4, n=5, theta=1.5, s0=np.array([4,3,2,1,0]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.886Z",
          "iopub.execute_input": "2021-03-30T07:54:20.902Z",
          "shell.execute_reply": "2021-03-30T07:54:22.447Z",
          "iopub.status.idle": "2021-03-30T07:54:20.933Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, the MM is given with the following equivalent expression\n",
        "$$p(\\sigma) \\propto \\phi^{d(\\sigma,\\sigma_0)},$$\n",
        "where $\\phi^{d(\\sigma,\\sigma_0)}=\\exp(-\\theta d(\\sigma,\\sigma_0))$ and \n",
        "for which the dispersion parameter is denoted as $\\phi\\in [0,1]$. We can relate the two dispersion parameters, $\\theta$ and $\\phi$, of the two expressions as  $\\phi=-\\log(\\theta)$. In this package, we can use also this second formulation by specifying parameter `phi` instead of `theta`. This functionallity holds for most funstions. The sampling, for example, is done then as follows:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mk.sampling_mm(m=4,n=5,phi=.5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:20.953Z",
          "iopub.execute_input": "2021-03-30T07:54:20.968Z",
          "iopub.status.idle": "2021-03-30T07:54:21.006Z",
          "shell.execute_reply": "2021-03-30T07:54:22.455Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "and the  trasformation between the two is as follows"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mk.theta_to_phi(0.7), mk.phi_to_theta(0.7)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.032Z",
          "iopub.execute_input": "2021-03-30T07:54:21.047Z",
          "iopub.status.idle": "2021-03-30T07:54:21.077Z",
          "shell.execute_reply": "2021-03-30T07:54:22.462Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected distance** The expected value of Kendall's-$\\tau$ distance under the MM is given by: \n",
        "$$\\mathbb{E}[D] = \\frac{n \\cdot \\exp(-\\theta)}{1 - \\exp(-\\theta)} - \\sum_{j=1}^n\\frac{j \\cdot \\exp(-j \\theta)}{1 - \\exp(-j \\theta)}$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "theta_mm = 0.7\n",
        "sample_mm = mk.sampling_mm(m=4,n=5,theta=1.5)\n",
        "expected_dist = mk.expected_dist_mm(n, theta_mm)\n",
        "expected_dist"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.098Z",
          "iopub.execute_input": "2021-03-30T07:54:21.111Z",
          "iopub.status.idle": "2021-03-30T07:54:21.140Z",
          "shell.execute_reply": "2021-03-30T07:54:22.469Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variance** The variance of Kendall's-$\\tau$ distance under the MM can be expressed as follows: \n",
        "$$\\mathbb{V}[D] = \\dfrac{ n \\cdot \\exp(-\\theta) }{ (1 - \\exp(-\\theta))^2 } - \\sum_{j=1}^n \\dfrac{ j^2\\exp(-j \\theta) }{ (1 - \\exp(-j \\theta))^2 }$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "variance_dist = mk.variance_dist_mm(n, theta_mm)\n",
        "variance_dist"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.158Z",
          "iopub.execute_input": "2021-03-30T07:54:21.172Z",
          "iopub.status.idle": "2021-03-30T07:54:21.207Z",
          "shell.execute_reply": "2021-03-30T07:54:22.479Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning** Then Borda algorithm allows to approximate the central permutation:  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.borda(sample_mm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.237Z",
          "iopub.execute_input": "2021-03-30T07:54:21.260Z",
          "iopub.status.idle": "2021-03-30T07:54:21.295Z",
          "shell.execute_reply": "2021-03-30T07:54:22.486Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `fit_mm` returns an approximation to the MLE of the parameters $\\sigma_0$ and $\\theta$. The consensus $\\sigma_0$ is approximated with the well known Borda count algorithm. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sigma_borda, phi_mm_mle = mk.fit_mm(sample_mm)\n",
        "print(sigma_borda)\n",
        "print(phi_mm_mle)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.317Z",
          "iopub.execute_input": "2021-03-30T07:54:21.330Z",
          "iopub.status.idle": "2021-03-30T07:54:21.367Z",
          "shell.execute_reply": "2021-03-30T07:54:22.493Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MM is also often defined as: $$p(\\sigma)=\\dfrac{\\phi^{d(\\sigma \\sigma_0^{-1})}}{\\prod_{\\substack{j=1}}^{n-1} \\frac{1-\\phi^{(n-j+1)}}{1 - \\phi}}$$ which implies that $\\phi = \\exp(-\\theta)$. The next function allows to obtain $\\theta$ given $\\phi$.\n",
        "\n",
        "*Remark:* $\\phi$ is in $[0,1]$ here."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "theta_mm_mle = mk.phi_to_theta(phi_mm_mle)\n",
        "theta_mm_mle"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.392Z",
          "iopub.execute_input": "2021-03-30T07:54:21.407Z",
          "iopub.status.idle": "2021-03-30T07:54:21.442Z",
          "shell.execute_reply": "2021-03-30T07:54:22.500Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mallows Model for Top-$k$ rankings"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition** A top-$k$ ranking ($k \\le n$) $\\sigma$ is a ranking $\\sigma = (\\sigma(1), \\sigma(2), \\dotsc, \\sigma(n))$ for which only the first $k$ ranks  are known. Hence ranks of items $i$ such that $\\sigma(i) \\le k$.\n",
        "\n",
        "An example of top-5 ranking (with $n=10$) with the package would be:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = np.array([ 4.,  0., np.NaN, 1., np.NaN, 3., np.NaN, 2., np.NaN, np.NaN])\n",
        "alpha"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.466Z",
          "iopub.execute_input": "2021-03-30T07:54:21.480Z",
          "iopub.status.idle": "2021-03-30T07:54:21.510Z",
          "shell.execute_reply": "2021-03-30T07:54:22.508Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling** In this part the sampling of the top-$k$ rankings is discussed.  \n",
        "Perhaps the most natural idea to generate top-$k$ rankings would be to generate the full rankings, using the Repeated Insertion Model for example, and to cut these obtained permutations after position $k$. This is possible, yet it seems computationally non-optimal with a complexity of $O(n^2)$.    \n",
        "\n",
        "Here we adapt the methods of previous sections to top-$k$ rankings. This method is based on sampling partially the inversion vectors. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice in the package, a top-$k$ ranking can be sampled as follows: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "m = 15\n",
        "n = 10 \n",
        "k = 5\n",
        "phi = 0.9 \n",
        "sigma_0 = np.array(range(10))\n",
        "sigma = np.random.permutation(n)\n",
        "sample_top_k = mk.sampling_top_k_rankings(m, n, k, phi = phi, s0=sigma_0)\n",
        "sample_top_k"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.534Z",
          "iopub.execute_input": "2021-03-30T07:54:21.549Z",
          "iopub.status.idle": "2021-03-30T07:54:21.581Z",
          "shell.execute_reply": "2021-03-30T07:54:22.515Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distance** In order to compare top-$k$ rankings, it is possible to use an extension of the classical Kendall's-$\\tau$ denoted as $p$-parametrized Kendall's-$\\tau$ distance (Fagin et al., 2003). \n",
        "\n",
        "In practice we can use it, chosing the $p$ parameter in $[0,1]$, as follows: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mk.p_kendall_tau(sample_top_k[0], sample_top_k[1], k=5, p=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.605Z",
          "iopub.execute_input": "2021-03-30T07:54:21.622Z",
          "iopub.status.idle": "2021-03-30T07:54:21.656Z",
          "shell.execute_reply": "2021-03-30T07:54:22.521Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mk.p_kendall_tau(sample_top_k[0], sample_top_k[1], k=5, p=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.680Z",
          "iopub.execute_input": "2021-03-30T07:54:21.696Z",
          "iopub.status.idle": "2021-03-30T07:54:21.730Z",
          "shell.execute_reply": "2021-03-30T07:54:22.528Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected distance** The expected value of Kendall's-$\\tau$ distance under the MM is given by: \n",
        "$$\\mathbb{E}[D] = \\frac{k \\cdot \\exp(-\\theta)}{1 - \\exp(-\\theta)} - \\sum_{j=n-k+1}^n\\frac{j \\cdot \\exp(-j \\theta)}{1 - \\exp(-j \\theta)}$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "expected_dist = mk.expected_dist_top_k(n,k,theta_mm)\n",
        "expected_dist"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.754Z",
          "iopub.execute_input": "2021-03-30T07:54:21.768Z",
          "iopub.status.idle": "2021-03-30T07:54:21.803Z",
          "shell.execute_reply": "2021-03-30T07:54:22.535Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variance** The variance of Kendall's-$\\tau$ distance under the MM can be expressed as follows: \n",
        "$$\\mathbb{V}[D] = \\dfrac{ k \\cdot \\exp(-\\theta) }{ (1 - \\exp(-\\theta))^2 } - \\sum_{j=n-k+1}^n \\dfrac{ j^2\\exp(-j \\theta) }{ (1 - \\exp(-j \\theta))^2 }$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "variance_dist = mk.variance_dist_top_k(n,k,theta_mm)\n",
        "variance_dist"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.826Z",
          "iopub.execute_input": "2021-03-30T07:54:21.843Z",
          "iopub.status.idle": "2021-03-30T07:54:21.879Z",
          "shell.execute_reply": "2021-03-30T07:54:22.543Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generalized Mallows Model (GMM) for complete permutations"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Generalized Mallows Model (GMM) is an extension of the Mallows Model, for which there are $n-1$ dispersion parameters $\\theta_j$ ($1 \\le j < n$), each affecting a particular position of the permutation.   \n",
        "Formally, the GMM under Kendall's-$\\tau$ distance is expressed as follows: \n",
        "\n",
        "$$p(\\sigma)=\\dfrac{\\exp(\\sum_{j=1}^{n-1}-\\theta_j V_j(\\sigma\\sigma_0^{-1}))}{\\psi(\\theta)}$$\n",
        "where $\\psi(\\theta) = \\prod_{j=1}^{n-1} \\psi_j(\\theta_j) = \\prod_{j=1}^{n-1} \\frac{1-\\exp(-\\theta_j(n-j+1))}{1 - \\exp(-\\theta_j)}$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_GMM(sigma, sigma_0, theta):\n",
        "    \n",
        "    n = len(sigma)\n",
        "        \n",
        "    sigma_0_inv = mk.inverse(sigma_0)\n",
        "    \n",
        "    V = mk.ranking_to_v(mk.compose(sigma, sigma_0_inv))\n",
        "    \n",
        "    psi = np.prod(np.array([(1 - np.exp(( - n + j ) * theta[j]))/(1 - np.exp(-theta[j])) for j in range(n-1)]))\n",
        "    \n",
        "    return np.exp( np.sum ( [ -theta[j] * V[j] for j in range(n-1) ] ) ) / psi \n",
        "    \n",
        "    \n",
        "sigma = np.array([3,1,2,0,4])\n",
        "sigma_0 = np.array(range(5))\n",
        "theta = [0.5,0.2,0.6,0.3]\n",
        "\n",
        "print(prob_GMM(sigma, sigma_0, theta))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.906Z",
          "iopub.execute_input": "2021-03-30T07:54:21.923Z",
          "iopub.status.idle": "2021-03-30T07:54:21.957Z",
          "shell.execute_reply": "2021-03-30T07:54:22.550Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling** It is also possible to sample the Generalized Mallows Models (GMM), using the same process as for the MM only with a change in the probability of $V_j$ as follows:\n",
        "\n",
        "$$p(V_j(\\sigma\\sigma_0^{-1}) = r) = \\frac{\\exp(-\\theta r)}{\\psi_j(\\theta)}, \\; \\forall r \\in {0, \\dotsc, n-j}$$\n",
        "\n",
        "In the package it is quite similar as for the classical Mallows Models, only that the dispersion parameter will be given as a list. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "m = 4000\n",
        "n = 5\n",
        "theta_gmm = [0.5,0.2,0.6,0.3]\n",
        "identity = np.array(range(n))\n",
        "sample_gmm = np.array(mk.sampling_gmm(m,theta_gmm))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:21.981Z",
          "iopub.execute_input": "2021-03-30T07:54:21.999Z",
          "iopub.status.idle": "2021-03-30T07:54:22.023Z",
          "shell.execute_reply": "2021-03-30T07:54:22.560Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected value of each term $V_j(\\sigma)$, where $\\sigma$ is a random Mallows permutation, is expressed as follows:\n",
        "$$ \\mathbb{E}[V_j] = \\frac{\\exp(-\\theta_j)}{1 - \\exp(-\\theta_j)} - \\frac{(n-j+1)\\exp(-\\theta_j(n-j+1))}{1 - \\exp(-\\theta_j(n-j+1))}, \\;\\forall j \\in \\{1, \\dotsc, n-1\\} $$\n",
        "And the values are computed as follows:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "expected_v_gmm = mk.expected_v(n, theta_gmm)\n",
        "print(expected_v_gmm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:22.044Z",
          "iopub.execute_input": "2021-03-30T07:54:22.057Z",
          "iopub.status.idle": "2021-03-30T07:54:22.085Z",
          "shell.execute_reply": "2021-03-30T07:54:22.567Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected value of Kendall's-$\\tau$ distance under the GMM is then given by: \n",
        "$$\\mathbb{E}[D] = \\sum_{j=1}^{n-1} \\mathbb{E}[V_j]$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "expected_dist_gmm = np.sum(expected_v_gmm)\n",
        "print(expected_dist_gmm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:22.106Z",
          "iopub.execute_input": "2021-03-30T07:54:22.119Z",
          "iopub.status.idle": "2021-03-30T07:54:22.147Z",
          "shell.execute_reply": "2021-03-30T07:54:22.575Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variance of each term $V_j(\\sigma)$ under the GMM can be expressed as follows: \n",
        "$$\\mathbb{V}[V_j] = \\dfrac{ \\exp(-\\theta_j) }{ (1 - \\exp(-\\theta_j))^2 } - \\sum_{j=1}^n \\frac{ (n-j+1)^2 \\exp(-(n-j+1) \\theta_j) }{ (1 - \\exp(-(n-j+1) \\theta_j))^2 }, \\;\\forall j \\in \\{1, \\dotsc, n-1\\} $$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "variance_v_gmm = mk.variance_v(n, theta_gmm)\n",
        "print(variance_v_gmm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:22.169Z",
          "iopub.execute_input": "2021-03-30T07:54:22.180Z",
          "iopub.status.idle": "2021-03-30T07:54:22.209Z",
          "shell.execute_reply": "2021-03-30T07:54:22.582Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected value of Kendall's-$\\tau$ distance under the GMM is then given by: \n",
        "$$\\mathbb{V}[D] = \\sum_{j=1}^{n-1} \\mathbb{V}[V_j]$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "variance_dist_gmm = np.sum(variance_v_gmm)\n",
        "print(variance_dist_gmm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:22.231Z",
          "iopub.execute_input": "2021-03-30T07:54:22.246Z",
          "iopub.status.idle": "2021-03-30T07:54:22.276Z",
          "shell.execute_reply": "2021-03-30T07:54:22.589Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning** An approximation to the MLE for $\\theta$ and $\\sigma_0$ given a sample of i.i.d Mallows permutations is as follows: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sigma_borda, theta_gmm_mle = mk.fit_gmm(sample_gmm)\n",
        "print(sigma_borda)\n",
        "print(theta_gmm_mle)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-03-30T07:54:22.296Z",
          "iopub.execute_input": "2021-03-30T07:54:22.309Z",
          "iopub.status.idle": "2021-03-30T07:54:22.338Z",
          "shell.execute_reply": "2021-03-30T07:54:22.595Z"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}